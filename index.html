<!DOCTYPE html>

<html lang="en">
<head>

  <title>Webcam</title>
</head>
<!-- Define the styles for the HTML elements -->

  <style>
    h1 {
      font-family: sans-serif;
      color: #333;
    }
    body {
      margin: 50px;
      filter: blur("0px");
      }
#videoElement {
  width: 80%;
  height: 80%;
  background-color: rgb(118, 104, 104);
  place-content: center;
}
  #title{
    font-family: sans-serif;
    font-size: 50px;
  }
  </style>

<body>
  <!-- Add the title and instructions for adding beats and using the hand recognition model -->

  <center>
  <h1 id="title"> BEATS by Ishan</h1>
  <div id="box">
    <h2> Press keys 1, 2, 3 to add beats. Press 0 to stop</h3>
  </div>
  <!-- <div id="container"> -->
    <video autoplay="true" id="videoElement">
    </video>
  <!-- </div> -->
  <div id="tempo"></div>
  <div id="hands">
    <h2> Wait for the camera border to turn Green. Then raise left hand to increase the tempo, right hand to decrease</h3>
  </div>
  <div id="hands">
    <h3> Sometimes, for the hand recognition model to work correctly, you will have to annoyingly inspect element, open the console, and reload</h3>
  </div>
  <button>start</button>
  </center>







<!-- Include the necessary JavaScript libraries -->

</script>
<script src="https://cdn.jsdelivr.net/npm/@mediapipe/pose"></script>
<script src="https://cdn.jsdelivr.net/npm/@tensorflow/tfjs-core"></script>
<script src="https://cdn.jsdelivr.net/npm/@tensorflow/tfjs-backend-webgl"></script>
<script src="https://cdn.jsdelivr.net/npm/@tensorflow-models/pose-detection"></script>
<script src="https://tonejs.github.io/build/Tone.js"></script>
<script type="text/javascript" src="https://cdnjs.cloudflare.com/ajax/libs/numbro/2.0.5/languages/nn.min.js"></script>

<script>
  let detector, video, osc, b
  var bpm = 120
  var temp_blur = 0

  // Function to add the video to the HTML body
  async function addVideo() {
    var video = document.querySelector("#videoElement");
    video.setAttribute('autoplay', '')
    video.setAttribute('muted', '')
    video.setAttribute('playsinline', '')
    document.body.appendChild(video)

    if (navigator.mediaDevices.getUserMedia) {
      navigator.mediaDevices.getUserMedia({ video: true })
        .then(function (stream) {
          video.srcObject = stream;
        })
        .catch(function (err0r) {
          console.log("Something went wrong!");
        });
    }
    return video
   
  }
  
  // Function to setup the hand recognition model
  // Taken from netnets.js

  async function setupModel () {
    const model = poseDetection.SupportedModels.BlazePose
    const detectorConfig = {
      runtime: 'mediapipe',
      solutionPath: 'https://cdn.jsdelivr.net/npm/@mediapipe/pose'
    }
    const detector = await poseDetection.createDetector(model, detectorConfig)
    return detector
  }
  
  const fileContentDiv = document.getElementById('tempo');
  
  
  // Function to reads the video feed and detects the hand
  // and based on that adjusts the tempo and blur
  async function draw () {
		const poses = await detector.estimatePoses(video)
    if (poses.length > 0) { 
      if (poses[0].keypoints[17].score > .8)
        {
          bpm+=1
          temp_blur+= .1
          console.log(poses[0].keypoints[17].name)
        }
      if (poses[0].keypoints[18].score > .8)
        {
          bpm-=1
          temp_blur-= .1
          console.log(poses[0].keypoints[18].name)
        }

      Tone.Transport.bpm.value = Math.max(bpm,1)
      fileContentDiv.innerHTML = "Tempo: " + bpm
      var title = document.querySelector("body");
      title.style.filter = "blur(" + temp_blur + "px)";
    }
    requestAnimationFrame(draw)
  }
  
  function wait(ms) 
  {
    return new Promise(resolve => setTimeout(resolve, ms));
  }

  async function setup () {
    console.log("Loading")
    document.body.style.background = 'pink'
    document.body.style.display = 'grid'
    document.body.style.justifyContent = 'center'
    document.body.style.alignItems = 'center'
    document.body.style.height = '100vh'
    video = await addVideo()
   	detector = await setupModel()
    var myDiv = document.getElementById("videoElement");
    // wait 5 second for the model to be ready
    await wait(5000);
    myDiv.style.border = "10px solid green"
    console.log('detector ready', detector)
    setTimeout(draw, 1000)  
  }



  const button = document.querySelector('button')
  const bass = new Tone.Player('bass1.mp3').toDestination()
  const snare = new Tone.Player('snare1.mp3').toDestination()
  const hhat = new Tone.Player('hhat1.mp3').toDestination()
  const hhat2 = new Tone.Player('hhat2.mp3').toDestination()
  const base_deeo = new Tone.Player('bass2.mp3').toDestination()
  let i = 0, j = 0, k = 0
 
  // setting up three different beats that correspond to the three different keys
  function beat_1 (time) {
    const b = (i % 4) + 1
    console.log(b)
    if (b === 1) {
    bass.start(time)
    document.body.style.background =  "red"
    }
    i++
  }

  function beat_2 (time) {
    const b = (j % 4) + 1
    console.log(b)
    if (b === 3) {
      snare.start(time)
      document.body.style.background = "blue"
    }
    j++
  }

  function beat_3 (time) {
    const b = (k % 4) + 1
    console.log(b)
    if (b === 2){ 
      base_deeo.start(time)
      document.body.style.background = "yellow"
    }
    k++
  }

  function toggle () {
    Tone.start();
    Tone.Transport.timeSignature = [4, 4]
  }



  // Function to add beats based on the key pressed
  function add_beat(e) {
    if (e.key === '1'){
    console.log("Pressing 1")
    Tone.Transport.stop()
    Tone.Transport.scheduleRepeat(beat_1, '4n')
    Tone.Transport.start()
    }
    else if (e.key === '2'){
      j = i
      console.log("Pressing 2")
      Tone.Transport.stop()
      Tone.Transport.scheduleRepeat(beat_2, '4n')
      Tone.Transport.start()
    }
    else if (e.key === '3'){
      k = i
      console.log("Pressing 3")
      Tone.Transport.stop()
      Tone.Transport.scheduleRepeat(beat_3, '4n')
      Tone.Transport.start()
    }
    else {
      e.key === '0'
      console.log("Rest")
      Tone.Transport.stop()
      i = k = j = 0
      bpm = 120
    }  
  }







  
  button.addEventListener('click', toggle)

  window.addEventListener('load', setup)

  window.addEventListener('keypress', add_beat)

</script>

</body>
</html>