<!DOCTYPE html>
<html lang="en">
<head>

  <title>Webcam</title>
</head>

  <style>
    h1 {
      font-family: sans-serif;
      color: #333;
    }
    body {
      margin: 50px;
      filter: blur("0px");
      }
  #container {
	margin: 0px auto;
  } 
  #videoElement {
    width: 500px;
    height: 500px;
    background-color: rgb(118, 104, 104);
    align-items: center;
  }
  #title{
    font-family: sans-serif;
    font-size: 50px;
  }
  </style>

<body>

  <center>
  <h1 id="title"> BEATS by Ishan</h1>
  <div id="box">
    <h2> Press keys 1, 2, 3 to add beats. Press 0 to stop</h3>
  </div>
  <div id="container">
    <video autoplay="true" id="videoElement">
    </video>
  </div>
  <div id="tempo"></div>
  <div id="hands">
    <h2> Raise left hand to increase the tempo, right hand to decrease</h3>
  </div>
  <div id="hands">
    <h3> First, for the hand recognition model to work correctly, you will have to annoyingly inspect element, open the console, and reload</h3>
  </div>
  <button>start</button>
  </center>








</script>
<script src="https://cdn.jsdelivr.net/npm/@mediapipe/pose"></script>
<script src="https://cdn.jsdelivr.net/npm/@tensorflow/tfjs-core"></script>
<script src="https://cdn.jsdelivr.net/npm/@tensorflow/tfjs-backend-webgl"></script>
<script src="https://cdn.jsdelivr.net/npm/@tensorflow-models/pose-detection"></script>
<script src="https://tonejs.github.io/build/Tone.js"></script>
<script type="text/javascript" src="https://cdnjs.cloudflare.com/ajax/libs/numbro/2.0.5/languages/nn.min.js"></script>

<script>
  let detector, video, osc, b
  var bpm = 120
  var temp_blur = 0
  async function addVideo() {
    var video = document.querySelector("#videoElement");
    video.setAttribute('autoplay', '')
    video.setAttribute('muted', '')
    video.setAttribute('playsinline', '')
    document.body.appendChild(video)

    if (navigator.mediaDevices.getUserMedia) {
      navigator.mediaDevices.getUserMedia({ video: true })
        .then(function (stream) {
          video.srcObject = stream;
        })
        .catch(function (err0r) {
          console.log("Something went wrong!");
        });
    }
    return video
   
  }
  
  
  async function setupModel () {
  
    const model = poseDetection.SupportedModels.BlazePose
  
    const detectorConfig = {
      runtime: 'mediapipe',
      solutionPath: 'https://cdn.jsdelivr.net/npm/@mediapipe/pose'
    }
  
    const detector = await poseDetection.createDetector(model, detectorConfig)
    return detector
  }
  
  const fileContentDiv = document.getElementById('tempo');
  async function draw () {
  
		const poses = await detector.estimatePoses(video)
    if (poses.length > 0) { 
        if (poses[0].keypoints[17].score > .8){
          bpm+=1
          temp_blur+= .1
          console.log(poses[0].keypoints[17].name)
        }
    if (poses[0].keypoints[18].score > .8){
        bpm-=1
        temp_blur-= .1
        console.log(poses[0].keypoints[18].name)
      }

      Tone.Transport.bpm.value = Math.max(bpm,1)
      fileContentDiv.innerHTML = "Tempo: " + bpm

      var title = document.querySelector("body");
      title.style.filter = "blur(" + temp_blur + "px)";
    }
      
      
    else {
    }
    requestAnimationFrame(draw)
  }


  async function setup () {
    console.log("Loading")
    document.body.style.background = 'pink'
    document.body.style.display = 'grid'
    document.body.style.justifyContent = 'center'
    document.body.style.alignItems = 'center'
    document.body.style.height = '100vh'
    video = await addVideo()

  	detector = await setupModel()
    var myDiv = document.getElementById("videoElement");

    if (detector){
      myDiv.style.border = "10px solid green"
      console.log('detector ready', detector)
    }
    else{
      myDiv.style.border = "10px solid red"
      console.log('detector not', detector)
      window.location.reload()
    }
    setTimeout(draw, 1000)  
  }



  const button = document.querySelector('button')
  const bass = new Tone.Player('bass1.mp3').toDestination()
  const snare = new Tone.Player('snare1.mp3').toDestination()
  const hhat = new Tone.Player('hhat1.mp3').toDestination()
  const base_deeo = new Tone.Player('bass2.mp3').toDestination()
  let i = 0, j = 0, k = 0
 
  function beat_1 (time) {
    const b = (i % 4) + 1
    console.log(b)
    if (b === 1) {
    bass.start(time)
    document.body.style.background =  "red"
    }
    i++
  }

  function beat_2 (time) {
    const b = (j % 4) + 1
    console.log(b)
    if (b === 1){
      bass.start(time)
      document.body.style.background = "green"
    }
    if (b === 3) {
      snare.start(time)
      document.body.style.background = "blue"
    }
    j++
  }

  function beat_3 (time) {
    const b = (k % 4) + 1
    console.log(b)
    if (b === 4){ 
      base_deeo.start(time)
      document.body.style.background = "yellow"
    }
    k++
  }

  function toggle () {
    Tone.start();
    Tone.Transport.timeSignature = [4, 4]
  }



  function add_beat(e) {
    if (e.key === '1'){
    console.log("Pressing 1")
    Tone.Transport.stop()
    Tone.Transport.scheduleRepeat(beat_1, '4n')
    Tone.Transport.start()
    }
    else if (e.key === '2'){
    j = i
    console.log("Pressing 2")
    Tone.Transport.stop()
    Tone.Transport.scheduleRepeat(beat_2, '4n')
    Tone.Transport.start()
    }
    else if (e.key === '3'){
    k = i
    console.log("Pressing 34")
    Tone.Transport.stop()
    Tone.Transport.scheduleRepeat(beat_3, '4n')
    Tone.Transport.start()
    }
    else {
      e.key === '0'
      console.log("Rest")
      Tone.Transport.stop()
      i = k = j = 0
      bpm = 120
    }  
  }







  
  button.addEventListener('click', toggle)

  window.addEventListener('load', setup)

  window.addEventListener('keypress', add_beat)

</script>

</body>
</html>